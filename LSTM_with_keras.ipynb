{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Davide Posillipo\n",
    "\n",
    "The data used from this notebook cannot be shared for confidentiality issues. The notebook is shared for educational purposes only. \n",
    "\n",
    "This code is mainly a Keras implementation of the paper \"Predictive Business Process Monitoring with LSTM Neural Networks\", https://arxiv.org/abs/1612.02130."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path (cwd): /Users/davideposillipo/Documents/Didattica/Sequences\n",
      "Verbose mode is activated!\n",
      "Tests mode is activated!\n"
     ]
    }
   ],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204687, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CE_CASE_ID</th>\n",
       "      <th>CE_ACTIVITY</th>\n",
       "      <th>CE_TIMESTAMP</th>\n",
       "      <th>CE_ACTIVITY_ORDER</th>\n",
       "      <th>event_label</th>\n",
       "      <th>tStamp_next</th>\n",
       "      <th>tStamp_prev</th>\n",
       "      <th>BPEM_event</th>\n",
       "      <th>BPEM_case</th>\n",
       "      <th>next_event</th>\n",
       "      <th>tDelta_next</th>\n",
       "      <th>tDelta_prev</th>\n",
       "      <th>tSince_casestart</th>\n",
       "      <th>tTotal</th>\n",
       "      <th>tRelativePosition</th>\n",
       "      <th>tSince_midnight</th>\n",
       "      <th>dWeekday</th>\n",
       "      <th>ranking</th>\n",
       "      <th>CE_GP_NR</th>\n",
       "      <th>CE_VNB_GP_NR</th>\n",
       "      <th>CE_VNB_GP_NAME</th>\n",
       "      <th>CE_LIEFERANT_NEU_NAME</th>\n",
       "      <th>CE_EVIPK_OH</th>\n",
       "      <th>CE_LIEFERANT_ALT_NAME_OH</th>\n",
       "      <th>CE_LIEFERANT_ALT_NR_OH</th>\n",
       "      <th>CE_SOURSYSTEM</th>\n",
       "      <th>CE_SPARTE_OH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>R4-00000001000007018636</td>\n",
       "      <td>1011 / 0010: Erster Prozessschritt: Lieferbeginn</td>\n",
       "      <td>2017-06-01 09:06:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-06-01 09:07:10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1011 / 0020: Auf Stamm- und Geschäftsdaten prüfen</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97254.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32770.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1536146195</td>\n",
       "      <td>NS00000060</td>\n",
       "      <td>Westnetz GmbH</td>\n",
       "      <td>RWE Rhein-Ruhr AG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>R4-00000001000007018636</td>\n",
       "      <td>1011 / 0020: Auf Stamm- und Geschäftsdaten prüfen</td>\n",
       "      <td>2017-06-01 09:07:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-01 09:07:12</td>\n",
       "      <td>2017-06-01 09:06:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1011 / 0030: Prüfen, ob Kündigung angestoßen w...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>97254.0</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>32830.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1536146195</td>\n",
       "      <td>NS00000060</td>\n",
       "      <td>Westnetz GmbH</td>\n",
       "      <td>RWE Rhein-Ruhr AG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>R4-00000001000007018636</td>\n",
       "      <td>1011 / 0030: Prüfen, ob Kündigung angestoßen w...</td>\n",
       "      <td>2017-06-01 09:07:12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-06-01 09:07:14</td>\n",
       "      <td>2017-06-01 09:07:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1011 / 0090: ES101 (Anmeldeanfrage) an Verteil...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>97254.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>32832.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1536146195</td>\n",
       "      <td>NS00000060</td>\n",
       "      <td>Westnetz GmbH</td>\n",
       "      <td>RWE Rhein-Ruhr AG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>R4-00000001000007018636</td>\n",
       "      <td>1011 / 0090: ES101 (Anmeldeanfrage) an Verteil...</td>\n",
       "      <td>2017-06-01 09:07:14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-06-01 09:07:21</td>\n",
       "      <td>2017-06-01 09:07:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1011 / 0110: Termin für den Empfang von CA100 ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97254.0</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>32834.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1536146195</td>\n",
       "      <td>NS00000060</td>\n",
       "      <td>Westnetz GmbH</td>\n",
       "      <td>RWE Rhein-Ruhr AG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>R4-00000001000007018636</td>\n",
       "      <td>1011 / 0110: Termin für den Empfang von CA100 ...</td>\n",
       "      <td>2017-06-01 09:07:21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-06-01 09:07:28</td>\n",
       "      <td>2017-06-01 09:07:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1011 / 0250: Termin für Empfang von ES200 (Zuo...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>97254.0</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>32841.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1536146195</td>\n",
       "      <td>NS00000060</td>\n",
       "      <td>Westnetz GmbH</td>\n",
       "      <td>RWE Rhein-Ruhr AG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CE_CASE_ID  \\\n",
       "518  R4-00000001000007018636   \n",
       "519  R4-00000001000007018636   \n",
       "520  R4-00000001000007018636   \n",
       "521  R4-00000001000007018636   \n",
       "522  R4-00000001000007018636   \n",
       "\n",
       "                                           CE_ACTIVITY        CE_TIMESTAMP  \\\n",
       "518   1011 / 0010: Erster Prozessschritt: Lieferbeginn 2017-06-01 09:06:10   \n",
       "519  1011 / 0020: Auf Stamm- und Geschäftsdaten prüfen 2017-06-01 09:07:10   \n",
       "520  1011 / 0030: Prüfen, ob Kündigung angestoßen w... 2017-06-01 09:07:12   \n",
       "521  1011 / 0090: ES101 (Anmeldeanfrage) an Verteil... 2017-06-01 09:07:14   \n",
       "522  1011 / 0110: Termin für den Empfang von CA100 ... 2017-06-01 09:07:21   \n",
       "\n",
       "     CE_ACTIVITY_ORDER  event_label         tStamp_next         tStamp_prev  \\\n",
       "518                1.0            3 2017-06-01 09:07:10                 NaT   \n",
       "519                2.0            4 2017-06-01 09:07:12 2017-06-01 09:06:10   \n",
       "520                3.0            5 2017-06-01 09:07:14 2017-06-01 09:07:10   \n",
       "521                8.0            6 2017-06-01 09:07:21 2017-06-01 09:07:12   \n",
       "522               10.0            7 2017-06-01 09:07:28 2017-06-01 09:07:14   \n",
       "\n",
       "     BPEM_event  BPEM_case                                         next_event  \\\n",
       "518           0          0  1011 / 0020: Auf Stamm- und Geschäftsdaten prüfen   \n",
       "519           0          0  1011 / 0030: Prüfen, ob Kündigung angestoßen w...   \n",
       "520           0          0  1011 / 0090: ES101 (Anmeldeanfrage) an Verteil...   \n",
       "521           0          0  1011 / 0110: Termin für den Empfang von CA100 ...   \n",
       "522           0          0  1011 / 0250: Termin für Empfang von ES200 (Zuo...   \n",
       "\n",
       "     tDelta_next  tDelta_prev  tSince_casestart   tTotal  tRelativePosition  \\\n",
       "518         60.0          0.0               0.0  97254.0           0.000000   \n",
       "519          2.0         60.0              60.0  97254.0           0.000617   \n",
       "520          2.0          2.0              62.0  97254.0           0.000638   \n",
       "521          7.0          2.0              64.0  97254.0           0.000658   \n",
       "522          7.0          7.0              71.0  97254.0           0.000730   \n",
       "\n",
       "     tSince_midnight  dWeekday  ranking    CE_GP_NR CE_VNB_GP_NR  \\\n",
       "518          32770.0         3      1.0  1536146195   NS00000060   \n",
       "519          32830.0         3      2.0  1536146195   NS00000060   \n",
       "520          32832.0         3      3.0  1536146195   NS00000060   \n",
       "521          32834.0         3      4.0  1536146195   NS00000060   \n",
       "522          32841.0         3      5.0  1536146195   NS00000060   \n",
       "\n",
       "    CE_VNB_GP_NAME CE_LIEFERANT_NEU_NAME  CE_EVIPK_OH  \\\n",
       "518  Westnetz GmbH     RWE Rhein-Ruhr AG            1   \n",
       "519  Westnetz GmbH     RWE Rhein-Ruhr AG            1   \n",
       "520  Westnetz GmbH     RWE Rhein-Ruhr AG            1   \n",
       "521  Westnetz GmbH     RWE Rhein-Ruhr AG            1   \n",
       "522  Westnetz GmbH     RWE Rhein-Ruhr AG            1   \n",
       "\n",
       "     CE_LIEFERANT_ALT_NAME_OH  CE_LIEFERANT_ALT_NR_OH CE_SOURSYSTEM  \\\n",
       "518                         0                       0            R4   \n",
       "519                         0                       0            R4   \n",
       "520                         0                       0            R4   \n",
       "521                         0                       0            R4   \n",
       "522                         0                       0            R4   \n",
       "\n",
       "     CE_SPARTE_OH  \n",
       "518             1  \n",
       "519             1  \n",
       "520             1  \n",
       "521             1  \n",
       "522             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(dir_data_pro/'data_for_christmas_finished.pkl')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CE_CASE_ID', 'CE_ACTIVITY', 'CE_TIMESTAMP', 'CE_ACTIVITY_ORDER',\n",
       "       'event_label', 'tStamp_next', 'tStamp_prev', 'BPEM_event', 'BPEM_case',\n",
       "       'next_event', 'tDelta_next', 'tDelta_prev', 'tSince_casestart',\n",
       "       'tTotal', 'tRelativePosition', 'tSince_midnight', 'dWeekday', 'ranking',\n",
       "       'CE_GP_NR', 'CE_VNB_GP_NR', 'CE_VNB_GP_NAME', 'CE_LIEFERANT_NEU_NAME',\n",
       "       'CE_EVIPK_OH', 'CE_LIEFERANT_ALT_NAME_OH', 'CE_LIEFERANT_ALT_NR_OH',\n",
       "       'CE_SOURSYSTEM', 'CE_SPARTE_OH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(X_enc, caseIDs, MAX_EVENTS=None):\n",
    "    print(\"Vectorizing preprocessed data...\")\n",
    " \n",
    "    num_samples = X_enc.shape[0]\n",
    "    num_features = X_enc.shape[1] \n",
    "    \n",
    "    X_vec = np.zeros((num_samples, MAX_EVENTS, num_features), dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    for caseID in np.unique(caseIDs):\n",
    "\n",
    "        rows = np.where(caseIDs == caseID)[0]\n",
    "        case_array = X_enc[rows, :]\n",
    "        len_sequence = case_array.shape[0]\n",
    "\n",
    "        for j in range(1, len_sequence + 1):\n",
    "            # input is array-content without caseID\n",
    "            X_vec[i, MAX_EVENTS - j:] = case_array[:j, ] \n",
    "            i += 1\n",
    "\n",
    "    return X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_encoder(df):\n",
    "    print(\"OneHotEncoding categorical features (drop_first=True)...\")\n",
    "    \n",
    "    categorical_features = list(df.select_dtypes(include=['object', 'category']).columns.values)\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Encoded the following  features:\")\n",
    "        for col in categorical_features:\n",
    "             print(f\"\\t{col}\")\n",
    "        print(\"Shape after encoding:\", df_encoded.shape)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CE_CASE_ID', 'CE_ACTIVITY', 'CE_TIMESTAMP', 'CE_ACTIVITY_ORDER',\n",
       "       'event_label', 'tStamp_next', 'tStamp_prev', 'BPEM_event', 'BPEM_case',\n",
       "       'next_event', 'tDelta_next', 'tDelta_prev', 'tSince_casestart',\n",
       "       'tTotal', 'tRelativePosition', 'tSince_midnight', 'dWeekday', 'ranking',\n",
       "       'CE_GP_NR', 'CE_VNB_GP_NR', 'CE_VNB_GP_NAME', 'CE_LIEFERANT_NEU_NAME',\n",
       "       'CE_EVIPK_OH', 'CE_LIEFERANT_ALT_NAME_OH', 'CE_LIEFERANT_ALT_NR_OH',\n",
       "       'CE_SOURSYSTEM', 'CE_SPARTE_OH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['CE_CASE_ID',\n",
    "             'CE_TIMESTAMP',\n",
    "             'CE_ACTIVITY_ORDER',\n",
    "             'event_label',\n",
    "             'tStamp_next',\n",
    "             'tStamp_prev',\n",
    "             'next_event',\n",
    "             'tDelta_next',\n",
    "             'tTotal',\n",
    "             'tRelativePosition',\n",
    "             'CE_VNB_GP_NR',\n",
    "             'CE_VNB_GP_NAME'\n",
    "            ], axis=1)\n",
    "\n",
    "caseID = df['CE_CASE_ID'].to_numpy()\n",
    "y_a = df['next_event'].to_numpy()\n",
    "y_t = df['tDelta_next'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoding categorical features (drop_first=True)...\n",
      "Encoded the following  features:\n",
      "\tCE_ACTIVITY\n",
      "\tCE_LIEFERANT_NEU_NAME\n",
      "\tCE_SOURSYSTEM\n",
      "Shape after encoding: (204687, 44)\n"
     ]
    }
   ],
   "source": [
    "X = oh_encoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_a_enc shape: (204687, 29)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_a_enc = lb.fit_transform(y_a); print(\"y_a_enc shape:\", y_a_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Features that do not suffer from data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['tSince_midnight'] = X['tSince_midnight'] / 86400\n",
    "X['dWeekday'] = X['dWeekday'] / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EVENTS = df.groupby(['CE_CASE_ID'], sort=False).apply(lambda x: len(x)).max()\n",
    "MAX_EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing preprocessed data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(204687, 43, 44)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec = vectorize(X.to_numpy(), caseID, MAX_EVENTS)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 2.0000000e+00, 6.2000000e+01,\n",
       "       3.8000000e-01, 4.2857143e-01, 3.0000000e+00, 1.5361462e+09,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec[2, -1, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BPEM_event', 'BPEM_case', 'tDelta_prev', 'tSince_casestart',\n",
       "       'tSince_midnight', 'dWeekday', 'ranking', 'CE_GP_NR', 'CE_EVIPK_OH',\n",
       "       'CE_LIEFERANT_ALT_NAME_OH', 'CE_LIEFERANT_ALT_NR_OH', 'CE_SPARTE_OH',\n",
       "       'CE_ACTIVITY_1011 - Lieferbeginn (Sicht Neuer Lieferant) / Abgelehnt [13] + Obsolet/Abgebrochen [05] + Storniert [04]',\n",
       "       'CE_ACTIVITY_1011 - Lieferbeginn (Sicht Neuer Lieferant) / Zu lösender BPEM-Fall [12] + Workflow-Fehler [11]',\n",
       "       'CE_ACTIVITY_1011 / 0010: Erster Prozessschritt: Lieferbeginn',\n",
       "       'CE_ACTIVITY_1011 / 0020: Auf Stamm- und Geschäftsdaten prüfen',\n",
       "       'CE_ACTIVITY_1011 / 0030: Prüfen, ob Kündigung angestoßen werden muss',\n",
       "       'CE_ACTIVITY_1011 / 0040: Prozess 1021 starten (Kündigung zwischen Lieferanten)',\n",
       "       'CE_ACTIVITY_1011 / 0050: Benachrichtigung von Prozess 1021 empfangen',\n",
       "       'CE_ACTIVITY_1011 / 0060: Termin für Prozess 1021',\n",
       "       'CE_ACTIVITY_1011 / 0070: Antwortergebnis von Prozess 1021 prüfen',\n",
       "       'CE_ACTIVITY_1011 / 0090: ES101 (Anmeldeanfrage) an Verteilnetzbetreiber senden',\n",
       "       'CE_ACTIVITY_1011 / 0100: CA100 (neg. APERAK) für ES101 vom VNB empfangen',\n",
       "       'CE_ACTIVITY_1011 / 0110: Termin für den Empfang von CA100 (neg. APERAK) für E',\n",
       "       'CE_ACTIVITY_1011 / 0120: ES102 (Anmeldeablehnung) v. Verteilnetzbetreiber empfa',\n",
       "       'CE_ACTIVITY_1011 / 0160: ES103 (Anmeldebestätigung) v. Verteilnetzbetreiber em',\n",
       "       'CE_ACTIVITY_1011 / 0170: ES103 gegen APERAK-Bedingung prüfen',\n",
       "       'CE_ACTIVITY_1011 / 0210: ES200 (Inform. über Zuordnung) vom VNB empfangen',\n",
       "       'CE_ACTIVITY_1011 / 0250: Termin für Empfang von ES200 (Zuordnungsinformationen',\n",
       "       'CE_ACTIVITY_1011 / 0260: Stammdaten anlegen',\n",
       "       'CE_ACTIVITY_1011 / 0270: Stammdaten bei Versorgungsszenario-Generierung aktuali',\n",
       "       'CE_ACTIVITY_1011 / 0290: Termin für Empfang von ES103 / ES102 (Antwort zur Anm',\n",
       "       'CE_ACTIVITY_1011 / 0899: Letzter Schritt und Ende des Prozesses',\n",
       "       'CE_ACTIVITY_1011 / 0905: Eingangsprüfungen Anmeldebestätigung - Sicht \"Neuer ',\n",
       "       'CE_ACTIVITY_1011 / 0910: Übernahme Dialogeingabe in Step-Daten',\n",
       "       'CE_ACTIVITY_1011 / 0920: Update der VEDM-Schnittstelle',\n",
       "       'CE_ACTIVITY_1011 / 0930: Prüfungen und Updates vor Anlage techn. Stammdaten',\n",
       "       'CE_ACTIVITY_1011 / 0940: Prüfungen und Updates nach Anlage techn. Stammdaten',\n",
       "       'CE_ACTIVITY_1011 / 0950: Prüfungen und Updates vor Einzug',\n",
       "       'CE_ACTIVITY_1011 / 0960: Prüfungen und Updates nach Einzug',\n",
       "       'CE_LIEFERANT_NEU_NAME_RWE Rhein-Ruhr AG (Gas)',\n",
       "       'CE_LIEFERANT_NEU_NAME_RWE Westfalen-Weser-Ems AG',\n",
       "       'CE_LIEFERANT_NEU_NAME_innogy SE (Gas)', 'CE_SOURSYSTEM_R8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.20\n",
    "\n",
    "caseID_train, caseID_test_temp, X_train, X_test_temp, y_a_train, y_a_test_temp, y_t_train, y_t_test_temp\\\n",
    "    = train_test_split(caseID, X_vec, y_a_enc, y_t, test_size=split_ratio, shuffle=True, stratify=y_a_enc, random_state=SEED)\n",
    "\n",
    "# Split val/test split from test data\n",
    "caseID_test, caseID_val, X_test, X_val, y_a_test, y_a_val, y_t_test, y_t_val\\\n",
    "    = train_test_split(caseID_test_temp, X_test_temp, y_a_test_temp, y_t_test_temp, test_size=0.5,\n",
    "                       shuffle=True, stratify=y_a_test_temp, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/caseID_test', caseID_test)\n",
    "np.save('data/X_test', X_test)\n",
    "np.save('data/y_a_test', y_a_test)\n",
    "np.save('data/y_t_test', y_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the variables in the vectorized form\n",
    "columns_to_rescale = [\"tDelta_prev\", \"tSince_casestart\"]\n",
    "idx_columns_to_rescale = [a for (a, b) in enumerate(X.columns) if b in columns_to_rescale]\n",
    "\n",
    "averages_train = np.mean(X_train, axis=(0, 1))[idx_columns_to_rescale]\n",
    "averages_dict_train = {x: y for (x, y) in zip(idx_columns_to_rescale, averages_train)}\n",
    "\n",
    "rescaling_parameters_train = {x: y for (x, y) in zip(columns_to_rescale, averages_train)}\n",
    "rescaling_parameters_train[\"tSince_midnight\"] = 86400\n",
    "rescaling_parameters_train[\"dWeekday\"] = 7\n",
    "y_t_train_mean = np.mean(y_t_train)\n",
    "rescaling_parameters_train[\"y_t_train_mean\"] = y_t_train_mean\n",
    "\n",
    "# rescaling using the information from the training set\n",
    "for idx in idx_columns_to_rescale:\n",
    "    X_train[:, :, idx] = X_train[:, :, idx]/averages_dict_train[idx]\n",
    "    X_val[:, :, idx] = X_val[:, :, idx] / averages_dict_train[idx]\n",
    "    X_test[:, :, idx] = X_test[:, :, idx] / averages_dict_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling time target variable\n",
    "y_t_train = y_t_train/y_t_train_mean\n",
    "y_t_test = y_t_test/y_t_train_mean\n",
    "y_t_val = y_t_val/y_t_train_mean\n",
    "\n",
    "train_data = [X_train, y_a_train, y_t_train]\n",
    "val_data = (X_val, y_a_val, y_t_val)\n",
    "test_data = [X_test, y_a_test, y_t_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54673.161356710574\n"
     ]
    }
   ],
   "source": [
    "print(y_t_train_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from google.protobuf import struct_pb2\n",
    "from tensorboard.plugins.hparams import summary as hparams_summary\n",
    "from tensorboard.plugins.hparams import api_pb2\n",
    "\n",
    "from evaluate_lstm import plot_history\n",
    "\n",
    "# ref: https://www.tensorflow.org/guide/gpu\n",
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, event_output_shape, hparams=None):\n",
    "    print('Creating the model...')\n",
    "\n",
    "    if hparams:\n",
    "        dropout = hparams['dropout_rate']\n",
    "        num_units = hparams['num_units']\n",
    "    else:\n",
    "        dropout = 0.2\n",
    "        num_units = 500\n",
    "\n",
    "    # Define the input Layer\n",
    "    input_layer = Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # Define the shared LSTM layer\n",
    "    # \"return_sequences\" must be true when stacking LSTMs\n",
    "    shared_layer = LSTM(num_units, implementation=2, return_sequences=True, dropout=dropout, recurrent_dropout=dropout)(input_layer)\n",
    "    shared_batch = BatchNormalization()(shared_layer)\n",
    "\n",
    "    # Define the layer specialized in event prediction\n",
    "    event_layer = LSTM(num_units, implementation=2, dropout=dropout, recurrent_dropout=dropout)(shared_batch)\n",
    "    event_batch = BatchNormalization()(event_layer)\n",
    "\n",
    "    # Define the layer specialized in time prediction\n",
    "    time_layer = LSTM(num_units, implementation=2, dropout=dropout, recurrent_dropout=dropout)(shared_batch)\n",
    "    time_batch = BatchNormalization()(time_layer)\n",
    "\n",
    "    # Define the output layers\n",
    "    event_output = Dense(event_output_shape, activation='softmax', name='event_output')(event_batch)\n",
    "    time_output = Dense(1, activation='relu', name='time_output')(time_batch)\n",
    "\n",
    "    # Create the model\n",
    "    # Includes all layers required in the computation of outputs given inputs\n",
    "    model = Model(inputs=input_layer, outputs=[event_output, time_output])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    print(hparams)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_callbacks(train_dir, hparams, tensorboard=False):\n",
    "    print('Creating the callbacks...')\n",
    "\n",
    "    if hparams:\n",
    "        redLR_pat = hparams['redLR_pat']\n",
    "        estop_pat = hparams['estop_pat']\n",
    "    else:\n",
    "        redLR_pat = 10\n",
    "        estop_pat = 12\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model Checkpoint\n",
    "    cp_dir = train_dir/'Checkpoints'\n",
    "    cp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cp_path = str(cp_dir) + '/cp_{epoch:04d}.h5'\n",
    "\n",
    "    callbacks.append(ModelCheckpoint(cp_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'))\n",
    "\n",
    "    # Create callbacks for model fitting\n",
    "    callbacks.append(EarlyStopping(monitor='val_loss', patience=estop_pat))\n",
    "    callbacks.append(ReduceLROnPlateau(monitor='val_loss', verbose=2, factor=0.5, patience=redLR_pat,\n",
    "                                       mode='auto', min_delta=0.0001, cooldown=0, min_lr=0))\n",
    "\n",
    "    if tensorboard:\n",
    "        callbacks.append(TensorBoard(dir_hparams / 'keras'))\n",
    "        print(\" -> Added Tensorboard to callbacks\")\n",
    "\n",
    "    print(\" -> callbacks created\")\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    return tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_data, val_data, hparams=None, tboard=False, verbose=1):\n",
    "\n",
    "    model_properties = f\"Model_\"\\\n",
    "        f\"eps_{hparams['epochs']:03d}_\" \\\n",
    "        f\"units_{hparams['num_units']:03d}_\" \\\n",
    "        f\"drop_{hparams['dropout_rate']:.2f}_\" \\\n",
    "        f\"lr_{hparams['learning_rate']:.4f}_\"\\\n",
    "        f\"red_{hparams['redLR_pat']:02d}_\" \\\n",
    "        f\"stop_{hparams['estop_pat']:02d}\" #\\\n",
    "        #+ str(datetime.now()).replace(\" \", \"_\")\n",
    "\n",
    "    train_dir = dir_models / model_properties\n",
    "\n",
    "    # Initialise data and parameters\n",
    "    X_train, y_a_train, y_t_train = train_data\n",
    "\n",
    "    if hparams:\n",
    "        learning_rate = hparams['learning_rate']\n",
    "        epochs = hparams['epochs']\n",
    "    else:\n",
    "        learning_rate = 0.002\n",
    "        epochs = 200\n",
    "\n",
    "    \"\"\" Creating and fitting the model \"\"\"\n",
    "    # Create the model\n",
    "    model = create_model(X_train.shape[1:], y_a_train.shape[1], hparams)\n",
    "\n",
    "    # Compile the model\n",
    "    # compile_model(model, learning_rate)\n",
    "    print(\"Compiling the model...\")\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam\n",
    "    model.compile(optimizer=Nadam(lr=learning_rate, epsilon=1e-08, clipvalue=3.),\n",
    "                  loss={'event_output': 'categorical_crossentropy', 'time_output': 'mae'}, # mae vs mse?\n",
    "                  #loss_weights={'event_output': 10., 'time_output': .5},\n",
    "                  metrics=['accuracy', 'mae'])\n",
    "\n",
    "    # Create the callbacks\n",
    "    callbacks = create_callbacks(train_dir, hparams, tensorboard=tboard)\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, {'event_output': y_a_train, 'time_output': y_t_train},\n",
    "                        validation_data=(val_data[0], {'event_output': y_a_val, 'time_output': val_data[2]}),\n",
    "                        batch_size=128, epochs=epochs, callbacks=None, verbose=verbose)\n",
    "                        #batch_size=32, epochs=epochs, callbacks=callbacks, verbose=verbose)\n",
    "        \n",
    "    \"\"\" Postprocessing \"\"\"\n",
    "\n",
    "    # Save the model\n",
    "    model.save(train_dir / 'final_model.h5')\n",
    "\n",
    "    # Save the training history\n",
    "    hist_df = pd.DataFrame.from_dict(history.history)\n",
    "    with open(train_dir / 'trainHistoryDict.csv', 'w', newline='') as handle:\n",
    "        hist_df.to_csv(handle, index=False)\n",
    "\n",
    "    # Load the training history\n",
    "    hist_df = pd.read_csv(train_dir / 'trainHistoryDict.csv')\n",
    "    hist_df = hist_df.to_dict()\n",
    "\n",
    "    # Plot the training history and save plots\n",
    "    plot_history(hist_df, train_dir)\n",
    "\n",
    "    return model, history, train_dir\n",
    "\n",
    "\n",
    "def init_training(train_data, val_data, units_list, dr_list, lr_list, epochs, redLR_patience, es_patience):\n",
    "    models = []\n",
    "    histories = []\n",
    "    train_dirs = []\n",
    "\n",
    "    for num_units in units_list:\n",
    "        for dropout_rate in dr_list:\n",
    "            for learning_rate in lr_list:\n",
    "                hparams = {\n",
    "                    'epochs': epochs,\n",
    "                    'num_units': num_units,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'redLR_pat': redLR_patience,\n",
    "                    'estop_pat': es_patience\n",
    "                }\n",
    "\n",
    "                model, history, train_dir = run_training(train_data, val_data, hparams)\n",
    "\n",
    "                models.append(model)\n",
    "                histories.append(history)\n",
    "                train_dirs.append(train_dir)\n",
    "\n",
    "    return models, histories, train_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Qr in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Sign in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Transpose in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 43, 44)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 43, 500)      1090000     input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 43, 500)      2000        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500)          2002000     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 500)          2002000     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500)          2000        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "event_output (Dense)            (None, 29)           14529       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_output (Dense)             (None, 1)            501         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 5,115,030\n",
      "Trainable params: 5,112,030\n",
      "Non-trainable params: 3,000\n",
      "__________________________________________________________________________________________________\n",
      "{'epochs': 2, 'num_units': 500, 'dropout_rate': 0.3, 'learning_rate': 0.001, 'redLR_pat': 10, 'estop_pat': 20}\n",
      "Compiling the model...\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Creating the callbacks...\n",
      " -> callbacks created\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 1/2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_train_function_13817 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " 116/1280 [=>............................] - ETA: 45:26 - loss: 3.5434 - event_output_loss: 2.3993 - time_output_loss: 1.1441 - event_output_accuracy: 0.2393 - event_output_mae: 0.0558 - time_output_accuracy: 0.0462 - time_output_mae: 1.1441"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-73c4d6b4baff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mes_patience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m                \u001b[0;31m# Patience before early stopping the Learning Process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredLR_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_patience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-6d90311f53e8>\u001b[0m in \u001b[0;36minit_training\u001b[0;34m(train_data, val_data, units_list, dr_list, lr_list, epochs, redLR_patience, es_patience)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 }\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6d90311f53e8>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(train_data, val_data, hparams, tboard, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m     history = model.fit(X_train, {'event_output': y_a_train, 'time_output': y_t_train},\n\u001b[1;32m     42\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'event_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_a_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         batch_size=128, epochs=epochs, callbacks=None, verbose=verbose)\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;31m#batch_size=32, epochs=epochs, callbacks=callbacks, verbose=verbose)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/sequences/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Start Training and Evaluate the Model\n",
    "#\n",
    "\"\"\"\n",
    "units_list = [500]              # Layer Output Dimension Space\n",
    "dr_list = [0.3]                 # dropout rates\n",
    "lr_list = [0.001]               # learning rates\n",
    "epochs = 2                    # Number of Iterations\n",
    "redLR_patience = 10             # Patience before reducing the Learning rate\n",
    "es_patience = 20                # Patience before early stopping the Learning Process\n",
    "\n",
    "models, histories, train_dirs = init_training(train_data, val_data, units_list, dr_list, lr_list, epochs, redLR_patience, es_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sequences)",
   "language": "python",
   "name": "sequences"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
